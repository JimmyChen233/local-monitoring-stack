# document for values.yaml: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
# for the "grafana:" section, all values from the grafana sub-chart can be used, found here: https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
# example grafana.ini configuration: https://github.com/prometheus-community/helm-charts/issues/2837
fullnameOverride: "system-prometheus"
cleanPrometheusOperatorObjectNames: true
crds:
  enabled: false

prometheusOperator:
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
  logLevel: info
  priorityClassName: dsh-daemon
  resources:
    requests:
      cpu: {{ .Values.prometheusOperator.resources.cpu }}
      memory: {{ .Values.prometheusOperator.resources.memory }}
    limits:
      memory: {{ .Values.prometheusOperator.resources.memory }}

  prometheusConfigReloader:
    resources:
      requests:
        cpu: 200m
        memory: 50Mi
      limits:
        cpu: 0  # this is a special override in the prometheus operator https://github.com/prometheus-operator/prometheus-operator/blob/0a93915921d2c4b1ac05db1bd4a1096b2026db08/cmd/operator/main.go#L174
        memory: 50Mi

defaultRules:
  labels:
    prometheus-selector-target: system-prometheus
  enabled: true
  rules:
    kubernetesApps: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
  disabled:
    InfoInhibitor: true
    KubePersistentVolumeFillingUp: true

alertmanager:
  enabled: {{.Values.alertmanager.enabled}}

grafana:
  enabled: true
  forceDeployDashboards: true

kubelet:
  enabled: true
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
    cAdvisorMetricRelabelings:
      # Drop less useful container CPU metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)'
      # Drop less useful container / always zero filesystem metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)'
      # Drop less useful / always zero container memory metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_memory_(mapped_file|swap)'
      # Drop less useful container process metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_(file_descriptors|tasks_state|threads_max)'
      # Drop container spec metrics that overlap with kube-state-metrics.
      - sourceLabels: [__name__]
        action: drop
        regex: 'container_spec.*'
      # Drop cgroup metrics with no pod.
      - sourceLabels: [id, pod]
        action: drop
        regex: '.+;'
    cAdvisorRelabelings:
      - action: replace
        sourceLabels: [__address__]
        targetLabel: hostname
        separator: ":"
        regex: "(.*):(.*)"
        replacement: "$1"
      # needed for some "k8s.rules" recording rules
      - targetLabel: metrics_path
        sourceLabels:
          - "__metrics_path__"
kubeApiServer:
  enabled: true
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus

    metricRelabelings:
      # Drop excessively noisy apiserver buckets.
      - action: drop
        regex: apiserver_request_slo_duration_seconds_bucket
        sourceLabels:
        - __name__
      - action: drop
        regex: apiserver_request_sli_duration_seconds_bucket
        sourceLabels:
        - __name__
      - action: drop
        regex: etcd_request_duration_seconds_bucket
        sourceLabels:
        - __name__

kubeControllerManager:
  enabled: false
  # we don't have it running
coreDns:
  enabled: false
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
kubeEtcd:
  enabled: true
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
kubeStateMetrics:
  enabled: true
  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
nodeExporter:
  enabled: true
prometheus-node-exporter:
  fullnameOverride: "prometheus-node-exporter"
  resources:
    requests:
      cpu: {{ .Values.prometheusNodeExporter.resources.cpu }}
      memory: {{ .Values.prometheusNodeExporter.resources.memory }}
    limits:
      memory: {{ .Values.prometheusNodeExporter.resources.memory }}
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
    - --collector.ethtool
    - --collector.processes
  prometheus:
    monitor:
      enabled: false

prometheus:
  enabled: true
  thanosService:
    enabled: true
  thanosServiceMonitor:
    enabled: true
    additionalLabels:
      prometheus-selector-target: system-prometheus
  serviceAccount:
    create: true
    name: "prometheus"

  serviceMonitor:
    additionalLabels:
      prometheus-selector-target: system-prometheus
  podDisruptionBudget:
    enabled: true
  prometheusSpec:
    logLevel: info
    {{- range list "serviceMonitor" "podMonitor" "rule" "probe" "scrapeConfig" }}
    {{ . }}NamespaceSelector: {}
    {{ . }}Selector:
      matchLabels:
        prometheus-selector-target: system-prometheus
    {{- end }}
    image:
      registry: registry.cp.kpn-dsh.com/quay.io
    resources:
      requests:
        cpu: {{ .Values.prometheus.resources.cpu }}
        memory: {{ .Values.prometheus.resources.memory }}
      limits:
        memory: {{ .Values.prometheus.resources.memory }}
    containers:
    - name: "prometheus"
      env:
      - name: GOMEMLIMIT
        # set GOMEMLIMIT: https://weaviate.io/blog/gomemlimit-a-game-changer-for-high-memory-applications
        # this is a complex function to automatically set this to 80% of what the pod limit is.
        value: "{{ floor (mulf (mulf (trimSuffix "Gi" .Values.prometheus.resources.memory) 1024) 0.8) }}MiB"
    replicas: {{ .Values.prometheus.replicas }}
    enableRemoteWriteReceiver: false
    enableAdminAPI: false
    walCompression: false
    retention: 1d

    additionalLabels:
      prometheus-selector-target: system-prometheus